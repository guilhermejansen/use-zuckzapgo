version: '3.7'

# =================== ZUCKZAPGO STACK PARA PORTAINER ===================
# Stack completa do ZuckZapGo com todos os serviços necessários
# Configurada para uso em produção com Docker Swarm via Portainer

services:
  zuckzapgo_private:
    # IMAGEM DISPONÍVEL: https://hub.docker.com/r/setupautomatizado/zuckzapgo-private
    image: setupautomatizado/zuckzapgo-private:latest # ou a versão que você deseja usar (exemplo: setupautomatizado/zuckzapgo-private:v1.0.0)
    networks:
      - network_public
    environment:
      # =================== ADMIN & AUTHENTICATION ===================
      - ZUCKZAPGO_ADMIN_TOKEN=SEU_TOKEN_AQUI_DO_ADMIN
      - ZUCKZAPGO_ADDRESS=api.seudominio.com
      - ZUCKZAPGO_PORT=8080

      - SERVER_IP=SEU_IP_AQUI #exemplo: 192.168.1.100
      - LICENSE_KEY=SUA_LICENÇA_AQUI_DA_ZUCKZAPGO
      - INSTANCE_ID=SUA_INSTANCE_NAME_AQUI #exemplo: zuckzapgo-1

      - LOG_TYPE=console # "console" ou "json"
      - LOG_COLOR=true # true ou false
      
      # =================== DATABASE CONFIGURATION ===================
      # Option 1: Individual database variables (current method)
      - DB_USER=zuckzapgo
      - DB_PASSWORD=SUA_SENHA_DO_BANCO_DE_DADOS # SENHA DO BANCO DE DADOS
      - DB_NAME=zuckzapgo # NOME DO BANCO DE DADOS
      - DB_HOST=postgres_zuckzapgo # NOME DO SERVIÇO DO BANCO DE DADOS
      - DB_PORT=5432
      - DB_SSLMODE=disable
      - DB_SCHEMA=public

      # Option 2: Single database connection string (production method)
      # Uncomment the line below and comment out the individual variables above
      # - DATABASE_URL=postgres://zuckzapgo:SUA_SENHA_DO_BANCO_DE_DADOS@postgres_zuckzapgo:5432/zuckzapgo?sslmode=disable&search_path=public
      # For managed databases: DATABASE_URL=postgres://user:pass@managed-db.example.com:5432/zuckzapgo?sslmode=require

      # =================== SESSION & TIMEZONE ===================
      - TZ=America/Sao_Paulo
      - SESSION_DEVICE_NAME=ZuckZapGo # NOME DO DISPOSITIVO

      # =================== WEBHOOK INDIVIDUAL POR INSTANICA CONFIGURATIONS ===================
      # "json" or "form" for the default
      - WEBHOOK_FORMAT=json 

      # Timeout principal da requisição HTTP
      - WEBHOOK_TIMEOUT=30s

      # Número máximo de tentativas de retry
      - WEBHOOK_MAX_RETRIES=3

      # Delay inicial entre tentativas
      - WEBHOOK_RETRY_DELAY=2s

      # Delay máximo entre tentativas (cap do backoff exponencial)
      - WEBHOOK_MAX_RETRY_DELAY=30s

      # Fator de multiplicação para backoff exponencial
      - WEBHOOK_BACKOFF_FACTOR=2.0

      # Número máximo de requisições simultâneas
      - WEBHOOK_MAX_CONCURRENCY=100

      # =================== GLOBAL SKIP MEDIA DOWNLOAD ===================
      # Enable/disable global skip media download for all users
      - GLOBAL_SKIP_MEDIA_DOWNLOAD=false
      # Skip events from WhatsApp groups
      - GLOBAL_SKIP_GROUPS=false
      # Skip events from WhatsApp newsletters
      - GLOBAL_SKIP_NEWSLETTERS=false
      # Skip events from WhatsApp broadcasts and status updates
      - GLOBAL_SKIP_BROADCASTS=false
      # Skip user's own messages (sent messages)
      - GLOBAL_SKIP_OWN_MESSAGES=false
      # Skip call events (offers, accepts, terminates)
      - GLOBAL_SKIP_CALLS=false

      # =================== GLOBAL S3 CONFIGURATION ===================
      # Enable/disable global S3 for media processing
      - GLOBAL_S3_ENABLED=false
      # S3 endpoint (leave empty for AWS S3)
      - GLOBAL_S3_ENDPOINT=
      # S3 region
      - GLOBAL_S3_REGION=us-east-1
      # S3 bucket name for global media
      - GLOBAL_S3_BUCKET=
      # S3 access key
      - GLOBAL_S3_ACCESS_KEY=
      # S3 secret key
      - GLOBAL_S3_SECRET_KEY=
      # Use path-style URLs (true for MinIO/compatible)
      - GLOBAL_S3_PATH_STYLE=true
      # Custom public URL for S3 objects (optional)
      - GLOBAL_S3_PUBLIC_URL=
      # Media delivery method: base64, url, or both
      - GLOBAL_S3_MEDIA_DELIVERY=base64
      # Retention days for media (0 = no expiration)
      - GLOBAL_S3_RETENTION_DAYS=0

      # =================== GLOBAL WEBHOOK CONFIGURATION ===================
      # Enable/disable global webhook for all users
      - GLOBAL_WEBHOOK_ENABLED=false 
      # URL endpoint to receive all global events
      - GLOBAL_WEBHOOK_URL=https://hook.prod.setupautomatizado.com/webhook/global-events
      # Event types to capture (comma-separated or "All")
      - GLOBAL_WEBHOOK_EVENTS=All
      # HTTP request timeout for webhook calls
      - GLOBAL_WEBHOOK_TIMEOUT=30s
      # Number of retry attempts for failed webhook calls
      - GLOBAL_WEBHOOK_RETRY_COUNT=3
      # Initial delay between retries
      - GLOBAL_WEBHOOK_RETRY_DELAY=2s
      # Maximum delay between retries (exponential backoff cap)
      - GLOBAL_WEBHOOK_MAX_RETRY_DELAY=30s
      # Exponential backoff multiplier for retry delays
      - GLOBAL_WEBHOOK_BACKOFF_FACTOR=2.0
      # Maximum concurrent webhook requests (production ready)
      - GLOBAL_WEBHOOK_CONCURRENCY=100

      # =================== GLOBAL RABBITMQ BASIC CONFIGURATION ===================
      # Enable/disable global RabbitMQ for all users
      - GLOBAL_RABBITMQ_ENABLED=false
      # RabbitMQ connection URL (production cluster)
      - GLOBAL_RABBITMQ_URL=amqp://zuckzapgo:SUA_SENHA_DO_RABBITMQ@rabbitmq_zuckzapgo:5672/zuckzapgo
      # Event types to publish (comma-separated or "All")
      - GLOBAL_RABBITMQ_EVENTS=All
      # Exchange name for global events
      - GLOBAL_RABBITMQ_EXCHANGE=zuckzapgo.global.prod
      - GLOBAL_RABBITMQ_EXCHANGE_TYPE=topic
      # Queue name for global events
      # ===== OPÇÃO 1: FILA ÚNICA (ATUAL) =====
      # GLOBAL_RABBITMQ_QUEUE=zuckzapgo.events
      # GLOBAL_RABBITMQ_ROUTING_KEY=events.#
      # ===== OPÇÃO 2: FILAS POR EVENTO (NOVO) =====
      - GLOBAL_RABBITMQ_QUEUE=zuckzapgo_{event_type}_events
      - GLOBAL_RABBITMQ_ROUTING_KEY=events.{event_type}.#
      # - GLOBAL_RABBITMQ_QUEUE=zuckzapgo.events.prod
      - GLOBAL_RABBITMQ_QUEUE_TYPE=classic
      # Routing key pattern for message routing
      - GLOBAL_RABBITMQ_ROUTING_KEY=events.#
      # Make exchange and queue durable (survive broker restart)
      - GLOBAL_RABBITMQ_DURABLE=true
      # Auto-delete exchange/queue when not in use
      - GLOBAL_RABBITMQ_AUTO_DELETE=false
      # Message delivery mode (2=persistent for production)
      - GLOBAL_RABBITMQ_DELIVERY_MODE=2
      # Exclusive queue for production stability
      - GLOBAL_RABBITMQ_EXCLUSIVE=false
      # No wait for queue creation
      - GLOBAL_RABBITMQ_NO_WAIT=false

      # =================== GLOBAL RABBITMQ PERFORMANCE TUNING (PRODUCTION) ===================
      # High-performance connection pool for production load
      - GLOBAL_RABBITMQ_CONNECTION_POOL_SIZE=50
      # High worker count for concurrent message processing
      - GLOBAL_RABBITMQ_WORKER_COUNT=100
      # Large buffer for high-volume message handling
      - GLOBAL_RABBITMQ_QUEUE_BUFFER_SIZE=100000
      # Enable message batching for maximum throughput
      - GLOBAL_RABBITMQ_ENABLE_BATCHING=true
      # Large batch size for production efficiency
      - GLOBAL_RABBITMQ_BATCH_SIZE=1000
      # Fast batch timeout for low latency
      - GLOBAL_RABBITMQ_BATCH_TIMEOUT_MS=100

      # =================== GLOBAL RABBITMQ RELIABILITY & RESILIENCE ===================
      # Circuit breaker: failures before opening circuit (production settings)
      - GLOBAL_RABBITMQ_CIRCUIT_BREAKER_THRESHOLD=20
      # Circuit breaker: longer timeout for production stability
      - GLOBAL_RABBITMQ_CIRCUIT_BREAKER_TIMEOUT_S=60
      # Extended timeout for individual publish operations
      - GLOBAL_RABBITMQ_PUBLISH_TIMEOUT_MS=10000
      # More retry attempts for production reliability
      - GLOBAL_RABBITMQ_MAX_RETRIES=5
      # Shorter delay between retries for faster recovery
      - GLOBAL_RABBITMQ_RETRY_DELAY_MS=500

      # =================== GLOBAL RABBITMQ MONITORING & LOGGING ===================
      # Frequent metrics collection for production monitoring
      - GLOBAL_RABBITMQ_METRICS_INTERVAL_S=5
      # Enable detailed logging for production troubleshooting
      - GLOBAL_RABBITMQ_ENABLE_DETAILED_LOGS=true
      # Enable metrics logging for production monitoring
      - GLOBAL_RABBITMQ_ENABLE_METRICS_LOG=true

      # =================== GLOBAL RABBITMQ QOS & MESSAGE SETTINGS ===================
      # High QoS prefetch for optimal message distribution
      - GLOBAL_RABBITMQ_QOS_PREFETCH_COUNT=200
      # Mandatory delivery for production reliability
      - GLOBAL_RABBITMQ_MANDATORY=false
      # No immediate flag for production stability
      - GLOBAL_RABBITMQ_IMMEDIATE=false

      # =================== GLOBAL RABBITMQ ADVANCED FEATURES (PRODUCTION) ===================
      # Enable compression for bandwidth optimization in production
      - GLOBAL_RABBITMQ_ENABLE_COMPRESSION=true
      # Enable persistence for production data durability
      - GLOBAL_RABBITMQ_ENABLE_PERSISTENCE=true
      # Enable confirmations for production reliability
      - GLOBAL_RABBITMQ_ENABLE_CONFIRMATION=true

    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints: [node.role == manager]
      resources:
        limits:
          cpus: "1" # QUANTIDADE DE CPU
          memory: 512MB # QUANTIDADE DE MEMÓRIA
      labels:
        - traefik.enable=true
        - traefik.http.routers.zuckzapgo_private.rule=Host(`api.seudominio.com`) # DOMINIO DA API
        - traefik.http.routers.zuckzapgo_private.entrypoints=websecure
        - traefik.http.routers.zuckzapgo_private.priority=1
        - traefik.http.routers.zuckzapgo_private.tls.certresolver=letsencryptresolver
        - traefik.http.routers.zuckzapgo_private.service=zuckzapgo_private
        - traefik.http.services.zuckzapgo_private.loadbalancer.server.port=8080
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # =================== BANCO DE DADOS POSTGRESQL ===================
  postgres_zuckzapgo:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=zuckzapgo # USUÁRIO DO BANCO DE DADOS
      - POSTGRES_PASSWORD=SUA_SENHA_DO_BANCO_DE_DADOS # SENHA DO BANCO DE DADOS
      - POSTGRES_DB=zuckzapgo # NOME DO BANCO DE DADOS
    volumes:
      - postgres_data_zuckzapgo:/var/lib/postgresql/data
    networks: 
      - network_public
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5' # QUANTIDADE DE CPU
          memory: 512MB # QUANTIDADE DE MEMÓRIA
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-zuckzapgo} -d ${POSTGRES_DB:-zuckzapgo}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # =================== RABBITMQ (MENSAGERIA) ===================
  rabbitmq_zuckzapgo:
    image: rabbitmq:4-management-alpine
    environment:
      - RABBITMQ_DEFAULT_USER=zuckzapgo # USUÁRIO DO RABBITMQ
      - RABBITMQ_DEFAULT_PASS=SUA_SENHA_DO_RABBITMQ # SENHA DO RABBITMQ
      - RABBITMQ_DEFAULT_VHOST=zuckzapgo # VHOST DO RABBITMQ
    volumes:
      - rabbitmq_data_zuckzapgo:/var/lib/rabbitmq
    networks:
      - network_public
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5' # QUANTIDADE DE CPU
          memory: 512MB # QUANTIDADE DE MEMÓRIA
      labels:
        - traefik.enable=true
        - traefik.http.routers.rabbitmq_zuckzapgo.rule=Host(`rabbitmq.seudominio.com`) # DOMINIO DO RABBITMQ
        - traefik.http.routers.rabbitmq_zuckzapgo.entrypoints=websecure
        - traefik.http.routers.rabbitmq_zuckzapgo.tls.certresolver=letsencryptresolver
        - traefik.http.routers.rabbitmq_zuckzapgo.service=rabbitmq_zuckzapgo
        - traefik.http.services.rabbitmq_zuckzapgo.loadbalancer.server.port=15672
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  postgres_data_zuckzapgo:
    name: postgres_data_zuckzapgo
    external: true
  rabbitmq_data_zuckzapgo:
    name: rabbitmq_data_zuckzapgo
    external: true

networks:
  network_public:
    name: network_public
    external: true
